{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Final Project Instructions**\n",
    "\n",
    "The following are instructions from Udacity's A/B Testing by Google Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Experiment Overview: Free Trial Screener"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment Overview: Free Trial Screener\n",
    "\n",
    "At the time of this experiment, Udacity courses currently have two options on the course overview page: \"start free trial\", and \"access course materials\". If the student clicks \"start free trial\", they will be asked to enter their credit card information, and then they will be enrolled in a free trial for the paid version of the course. After 14 days, they will automatically be charged unless they cancel first. If the student clicks \"access course materials\", they will be able to view the videos and take the quizzes for free, but they will not receive coaching support or a verified certificate, and they will not submit their final project for feedback.\n",
    "\n",
    "In the experiment, Udacity tested a change where if the student clicked \"start free trial\", they were asked how much time they had available to devote to the course. If the student indicated 5 or more hours per week, they would be taken through the checkout process as usual. If they indicated fewer than 5 hours per week, a message would appear indicating that Udacity courses usually require a greater time commitment for successful completion, and suggesting that the student might like to access the course materials for free. At this point, the student would have the option to continue enrolling in the free trial, or access the course materials for free instead. This screenshot shows what the experiment looks like.\n",
    "\n",
    "**The hypothesis was that this might set clearer expectations for students upfront, thus reducing the number of frustrated students who left the free trial because they didn't have enough timeâ€”without significantly reducing the number of students to continue past the free trial and eventually complete the course. If this hypothesis held true, Udacity could improve the overall student experience and improve coaches' capacity to support students who are likely to complete the course.** \n",
    "\n",
    "*My notes: My interpretation of the above paragraphs is that \"Does providing a choice based on number of hours one enters at the 'Start free trial' prompt influence retention?\" *\n",
    "\n",
    " *Some immediate metrics come to my mind:*\n",
    "\n",
    "- *Evaluate the ratio of (total number of students completing course)/(total number of students enrolled in free trial). This should be high should the hypothesis be true.*\n",
    "- *Evaluate the ratio of (total number of students staying in free trial)/(total number of students enrolled in free trial). This should also be high should the hypothesis be true.*\n",
    "\n",
    "The unit of diversion is a cookie, although if the student enrolls in the free trial, they are tracked by user-id from that point forward. The same user-id cannot enroll in the free trial twice. For users that do not enroll, their user-id is not tracked in the experiment, even if they were signed in when they visited the course overview page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metric choice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Which of the following metrics would you choose to measure for this experiment and why? For each metric you choose, indicate whether you would use it as an invariant metric or an evaluation metric. The practical significance boundary for each metric, that is, the difference that would have to be observed before that was a meaningful change for the business, is given in parentheses. All practical significance boundaries are given as absolute changes.\n",
    "\n",
    "Any place \"unique cookies\" are mentioned, the uniqueness is determined by day. (That is, the same cookie visiting on different days would be counted twice.) User-ids are automatically unique since the site does not allow the same user-id to enroll twice.\n",
    "\n",
    "- **Number of cookies**: That is, number of unique cookies to view the course overview page. (dmin=3000)\n",
    "\n",
    "    *My response: Since the experiment is whether a choice is provided after the \"Start free trial\" prompt, it seems that the number of cookies to view the course overview page is not helpful for the experiment, since the enrollment choice follows this page. I would choose this as an invariant metric.*\n",
    "\n",
    "\n",
    "- **Number of user-ids**: That is, number of users who enroll in the free trial. (dmin=50)\n",
    "\n",
    "    *My response: This is a critical metric to use in evaluation. It can be used to determine whether those that saw the screening prompt were more likely to enroll. It can also serve as the denominator for other metrics. (In my submitted answers, if I included this as an evaluation metric, I deduced that this \"wouldn't be relevant to evaluating the experiment\". However, I do not understand how \"retention\" would be evaluated without this.) *\n",
    "\n",
    "\n",
    "- **Number of clicks**: That is, number of unique cookies to click the \"Start free trial\" button (which happens before the free trial screener is trigger). (dmin=240)\n",
    "\n",
    "    *My response: This is a good thing to monitor as an invariant metric. The students who enroll (based on number of clicks in this context) can be binned into equal groups of those that are asked how much time they had available to devote to the course and those that are not asked. *\n",
    "\n",
    "\n",
    "- **Click-through-probability**: That is, number of unique cookies to click the \"Start free trial\" button divided by number of unique cookies to view the course overview page. (dmin=0.01)\n",
    "\n",
    "    *My response: Similar to the explanation for the number of cookies metric, I would choose this as an invariant metric. The critical part of the experiment happens after the \"Start free trial\" button is pressed. This metric is relevant at the course overview page which occurs before the experiment starts.*\n",
    "\n",
    "\n",
    "- **Gross conversion**: That is, number of user-ids to complete checkout and enroll in the free trial divided by number of unique cookies to click the \"Start free trial\" button. (dmin= 0.01)\n",
    "\n",
    "    *My response: This is a metric that can be used in evaluation but it will require further segmentation by whether they were in the control or treatment group.*\n",
    "\n",
    "\n",
    "- **Retention**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by number of user-ids to complete checkout. (dmin=0.01)\n",
    "\n",
    "    *My response: This is one of the critical metrics that I proposed in my notes above. You would hypothesize that retention is higher in the group that observed the \"free trial screener\" prompt and entered 5 or higher versus the control, those that did not receive the \"free trial prompt\" at all.*\n",
    "\n",
    "\n",
    "- **Net conversion**: That is, number of user-ids to remain enrolled past the 14-day boundary (and thus make at least one payment) divided by the number of unique cookies to click the \"Start free trial\" button. (dmin= 0.0075)\n",
    "\n",
    "    *My response: Like gross conversion, this is a metric that can be used in evaluation but it will require further segmentation by whether they were in the control or treatment group.*\n",
    "\n",
    "\n",
    "You should also decide now what results you will be looking for in order to launch the experiment. Would a change in any one of your evaluation metrics be sufficient? Would you want to see multiple metrics all move or not move at the same time in order to launch? This decision will inform your choices while designing the experiment.\n",
    "\n",
    "*My response: Before deciding on launch, I would first check that the invariant metrics are not revealing any differences between the control or experimental groups. If the invariant metrics are behaving as expected, I would want the \"Number of user-ids\" and my \"retention\" in the experimental group to be at least as high as their respective practical significance boundaries compared to the control group to consider recommending launch.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Measuring Variability"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This spreadsheet (*I put the values down below*) contains rough estimates of the baseline values for these metrics (again, these numbers have been changed from Udacity's true numbers).\n",
    "\n",
    "For each metric you selected as an evaluation metric, estimate its standard deviation analytically. Do you expect the analytic estimates to be accurate? That is, for which metrics, if any, would you want to collect an empirical estimate of the variability if you had time?\n",
    "\n",
    "| Feature | Value |\n",
    "| --- | --- |\n",
    "| Unique cookies to view course overview page per day | 40000 | \n",
    "| Unique cookies to click \"Start free trial\" per day | 3200 |\n",
    "| Enrollments per day |\t660 |\n",
    "| Click-through-probability on \"Start free trial\" |\t0.08 |\n",
    "| Probability of enrolling, given click | 0.20625 |\n",
    "| Probability of payment, given enroll | 0.53 |\n",
    "| Probability of payment, given click | 0.1093125 |\n",
    "\n",
    "Assume 5000 cookies visit the course overview page. Enter each estimate to 4 decimal places.\n",
    "\n",
    "*My response: First, it is important to focus on the metrics used for evaluation which were determined in the previous section. Those metrics were gross conversion, retention, and net conversion.\n",
    "\n",
    "- **Gross conversion** = (number of user-ids to complete checkout and enroll in the free trial)/(number of unique cookies to click the \"Start free trial\" button)\n",
    "\n",
    "- **Retention** = (number of user-ids to remain enrolled past the 14-day boundary and pay)/(number of user-ids to complete checkout)\n",
    "\n",
    "- **Net conversion** = (number of user-ids to remain enrolled past the 14-day boundary and pay)/(number of unique cookies to click the \"Start free trial\" button)\n",
    "\n",
    "\n",
    "To measure each standard deviation analytically for gross conversion, \n",
    " = Probability of payment, given enroll * Unique cookies to click \"Start free trial\" per day\n",
    " = 0.53 x 3200\n",
    "\n",
    "Probability of payment, given enroll | 0.53\n",
    "\n",
    "om the baseline values, I would take each value\n",
    "\n",
    "40000\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "This is one of the critical metrics that I proposed in my notes above. You would hypothesize that retention is higher in the group that observed the \"free trial screener\" prompt and entered 5 or higher versus the control, those that did not receive the \"free trial prompt\" at all.*\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
