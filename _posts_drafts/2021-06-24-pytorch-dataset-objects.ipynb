{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "settled-international",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Working with PyTorch's Dataset and Dataloader classes (part 1)\"\n",
    "mathjax: true\n",
    "toc: true\n",
    "toc_sticky: true\n",
    "categories: [data science, statistics]\n",
    "---\n",
    "\n",
    "Recently, I built a simple NLP algorithm for a work project, following the template described in [this tutorial](https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#sphx-glr-beginner-nlp-deep-learning-tutorial-py). As I looked to increase my model's complexity, I started to come across references to [Dataset and Dataloader](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) classes. I tried adapting my work-related code to use these objects, but I found myself running into [pesky bugs](https://media.giphy.com/media/xwEVCKetQWpeYyumJJ/giphy.gif). I thought I should take some time to figure out how to properly use `Dataset` and `Dataloader` objects. In this post, I adapt the PyTorch NLP tutorial to work with `Dataset` and `Dataloader` objects. Since my focus is primarily on using these objects, please refer to the [tutorial](https://pytorch.org/tutorials/beginner/nlp/deep_learning_tutorial.html#sphx-glr-beginner-nlp-deep-learning-tutorial-py) for details regarding the NLP model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "funny-version",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:32.672419Z",
     "start_time": "2021-06-25T03:05:31.763086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fef88a746f0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "torch.manual_seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "breathing-turkey",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:33.718726Z",
     "start_time": "2021-06-25T03:05:33.609398Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 2;\n",
       "                var nbb_unformatted_code = \"%load_ext nb_black\\n%config InlineBackend.figure_format = 'retina'\\n%load_ext watermark\";\n",
       "                var nbb_formatted_code = \"%load_ext nb_black\\n%config InlineBackend.figure_format = 'retina'\\n%load_ext watermark\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%load_ext nb_black\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "%load_ext watermark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "hidden-luxembourg",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:34.232651Z",
     "start_time": "2021-06-25T03:05:34.224641Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 3;\n",
       "                var nbb_unformatted_code = \"# Figure aesthetics\\nsns.set_theme()\\nsns.set_context(\\\"talk\\\")\\nsns.set_style(\\\"white\\\")\";\n",
       "                var nbb_formatted_code = \"# Figure aesthetics\\nsns.set_theme()\\nsns.set_context(\\\"talk\\\")\\nsns.set_style(\\\"white\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Figure aesthetics\n",
    "sns.set_theme()\n",
    "sns.set_context(\"talk\")\n",
    "sns.set_style(\"white\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e837a5b5",
   "metadata": {},
   "source": [
    "# First attempt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eada6bc4",
   "metadata": {},
   "source": [
    "The tutorial generates a simple dataset to use for a logistic regression bag-of-words classifier. It takes a sentence and trains whether the sentence is in English or Spanish. The data was structured originally so each sample was a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41d77779",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:37.680082Z",
     "start_time": "2021-06-25T03:05:37.667793Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 4;\n",
       "                var nbb_unformatted_code = \"train_data = [\\n    (\\\"me gusta comer en la cafeteria\\\".split(), \\\"SPANISH\\\"),\\n    (\\\"Give it to me\\\".split(), \\\"ENGLISH\\\"),\\n    (\\\"No creo que sea una buena idea\\\".split(), \\\"SPANISH\\\"),\\n    (\\\"No it is not a good idea to get lost at sea\\\".split(), \\\"ENGLISH\\\"),\\n]\\n\\ntest_data = [\\n    (\\\"Yo creo que si\\\".split(), \\\"SPANISH\\\"),\\n    (\\\"it is lost on me\\\".split(), \\\"ENGLISH\\\"),\\n]\";\n",
       "                var nbb_formatted_code = \"train_data = [\\n    (\\\"me gusta comer en la cafeteria\\\".split(), \\\"SPANISH\\\"),\\n    (\\\"Give it to me\\\".split(), \\\"ENGLISH\\\"),\\n    (\\\"No creo que sea una buena idea\\\".split(), \\\"SPANISH\\\"),\\n    (\\\"No it is not a good idea to get lost at sea\\\".split(), \\\"ENGLISH\\\"),\\n]\\n\\ntest_data = [\\n    (\\\"Yo creo que si\\\".split(), \\\"SPANISH\\\"),\\n    (\\\"it is lost on me\\\".split(), \\\"ENGLISH\\\"),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data = [\n",
    "    (\"me gusta comer en la cafeteria\".split(), \"SPANISH\"),\n",
    "    (\"Give it to me\".split(), \"ENGLISH\"),\n",
    "    (\"No creo que sea una buena idea\".split(), \"SPANISH\"),\n",
    "    (\"No it is not a good idea to get lost at sea\".split(), \"ENGLISH\"),\n",
    "]\n",
    "\n",
    "test_data = [\n",
    "    (\"Yo creo que si\".split(), \"SPANISH\"),\n",
    "    (\"it is lost on me\".split(), \"ENGLISH\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26a54c05",
   "metadata": {},
   "source": [
    "Before putting the data into the `Dataset` object, I'll organize it into a dataframe for easier input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6cf76aa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:39.001717Z",
     "start_time": "2021-06-25T03:05:38.987090Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[me, gusta, comer, en, la, cafeteria]</td>\n",
       "      <td>SPANISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Give, it, to, me]</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[No, creo, que, sea, una, buena, idea]</td>\n",
       "      <td>SPANISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[No, it, is, not, a, good, idea, to, get, lost...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Yo, creo, que, si]</td>\n",
       "      <td>SPANISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[it, is, lost, on, me]</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words   labels\n",
       "0              [me, gusta, comer, en, la, cafeteria]  SPANISH\n",
       "1                                 [Give, it, to, me]  ENGLISH\n",
       "2             [No, creo, que, sea, una, buena, idea]  SPANISH\n",
       "3  [No, it, is, not, a, good, idea, to, get, lost...  ENGLISH\n",
       "4                                [Yo, creo, que, si]  SPANISH\n",
       "5                             [it, is, lost, on, me]  ENGLISH"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 5;\n",
       "                var nbb_unformatted_code = \"# Combine so we have one data object\\ndata = train_data + test_data\\n\\n# Put into a dataframe\\ndf_data = pd.DataFrame(data)\\ndf_data.columns = [\\\"words\\\", \\\"labels\\\"]\\ndf_data\";\n",
       "                var nbb_formatted_code = \"# Combine so we have one data object\\ndata = train_data + test_data\\n\\n# Put into a dataframe\\ndf_data = pd.DataFrame(data)\\ndf_data.columns = [\\\"words\\\", \\\"labels\\\"]\\ndf_data\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Combine so we have one data object\n",
    "data = train_data + test_data\n",
    "\n",
    "# Put into a dataframe\n",
    "df_data = pd.DataFrame(data)\n",
    "df_data.columns = [\"words\", \"labels\"]\n",
    "df_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d78c8b",
   "metadata": {},
   "source": [
    "## Putting the data in `Dataset` and output with `Dataloader`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "379031e0",
   "metadata": {},
   "source": [
    "Now it is time to put the data into a `Dataset` object. I referred to [PyTorch's tutorial on datasets and dataloaders](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html#) and [this helpful example specific to custom text](https://towardsdatascience.com/how-to-use-datasets-and-dataloader-in-pytorch-for-custom-text-data-270eed7f7c00), especially for making my own dataset class, which is shown here. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a7ccda41",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:41.070893Z",
     "start_time": "2021-06-25T03:05:41.056610Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 6;\n",
       "                var nbb_unformatted_code = \"class TextDataset(Dataset):\\n    \\\"\\\"\\\"\\n    Characterizes the pre-processed SRF custom dataset for PyTorch\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, ids, text, labels):\\n        \\\"\\\"\\\"\\n        Initialization. Ids can be useful after splitting the dataset.\\n        \\\"\\\"\\\"\\n        self.ids = ids\\n        self.text = text\\n        self.labels = labels\\n\\n    def __len__(self):\\n        \\\"\\\"\\\"\\n        This is simply the number of labels in the dataseta.\\n        \\\"\\\"\\\"\\n        return len(self.labels)\\n\\n    def __getitem__(self, idx):\\n        \\\"\\\"\\\"\\n        Generate one sample of data\\n        \\\"\\\"\\\"\\n        label = self.labels[idx]\\n        text = self.text[idx]\\n        sample = {\\\"Text\\\": text, \\\"Label\\\": label}\\n        return sample\";\n",
       "                var nbb_formatted_code = \"class TextDataset(Dataset):\\n    \\\"\\\"\\\"\\n    Characterizes the pre-processed SRF custom dataset for PyTorch\\n    \\\"\\\"\\\"\\n\\n    def __init__(self, ids, text, labels):\\n        \\\"\\\"\\\"\\n        Initialization. Ids can be useful after splitting the dataset.\\n        \\\"\\\"\\\"\\n        self.ids = ids\\n        self.text = text\\n        self.labels = labels\\n\\n    def __len__(self):\\n        \\\"\\\"\\\"\\n        This is simply the number of labels in the dataseta.\\n        \\\"\\\"\\\"\\n        return len(self.labels)\\n\\n    def __getitem__(self, idx):\\n        \\\"\\\"\\\"\\n        Generate one sample of data\\n        \\\"\\\"\\\"\\n        label = self.labels[idx]\\n        text = self.text[idx]\\n        sample = {\\\"Text\\\": text, \\\"Label\\\": label}\\n        return sample\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class TextDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Characterizes the pre-processed SRF custom dataset for PyTorch\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, ids, text, labels):\n",
    "        \"\"\"\n",
    "        Initialization. Ids can be useful after splitting the dataset.\n",
    "        \"\"\"\n",
    "        self.ids = ids\n",
    "        self.text = text\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"\n",
    "        This is simply the number of labels in the dataseta.\n",
    "        \"\"\"\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Generate one sample of data\n",
    "        \"\"\"\n",
    "        label = self.labels[idx]\n",
    "        text = self.text[idx]\n",
    "        sample = {\"Text\": text, \"Label\": label}\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "db7bd9d4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:41.742765Z",
     "start_time": "2021-06-25T03:05:41.729593Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 7;\n",
       "                var nbb_unformatted_code = \"# Put train and test into dataset objects\\ntrain_ids = range(0, 4)\\ntest_ids = range(4, 6)\\n\\ntrain_DS1 = TextDataset(\\n    train_ids,\\n    df_data.loc[train_ids, \\\"words\\\"].tolist(),\\n    df_data.loc[train_ids, \\\"labels\\\"].tolist(),\\n)\\n\\ntest_DS1 = TextDataset(\\n    train_ids,\\n    df_data.loc[test_ids, \\\"words\\\"].tolist(),\\n    df_data.loc[test_ids, \\\"labels\\\"].tolist(),\\n)\";\n",
       "                var nbb_formatted_code = \"# Put train and test into dataset objects\\ntrain_ids = range(0, 4)\\ntest_ids = range(4, 6)\\n\\ntrain_DS1 = TextDataset(\\n    train_ids,\\n    df_data.loc[train_ids, \\\"words\\\"].tolist(),\\n    df_data.loc[train_ids, \\\"labels\\\"].tolist(),\\n)\\n\\ntest_DS1 = TextDataset(\\n    train_ids,\\n    df_data.loc[test_ids, \\\"words\\\"].tolist(),\\n    df_data.loc[test_ids, \\\"labels\\\"].tolist(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Put train and test into dataset objects\n",
    "train_ids = range(0, 4)\n",
    "test_ids = range(4, 6)\n",
    "\n",
    "train_DS1 = TextDataset(\n",
    "    train_ids,\n",
    "    df_data.loc[train_ids, \"words\"].tolist(),\n",
    "    df_data.loc[train_ids, \"labels\"].tolist(),\n",
    ")\n",
    "\n",
    "test_DS1 = TextDataset(\n",
    "    train_ids,\n",
    "    df_data.loc[test_ids, \"words\"].tolist(),\n",
    "    df_data.loc[test_ids, \"labels\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72f5e76",
   "metadata": {},
   "source": [
    "When putting the data into their respective dataset objects, it is important to use the `.tolist()` method or else `DataLoader` will return an error when retrieving the data. Now let's use `DataLoader` and a simple for loop to return the values of the data. I'll use only the training data and a `batch_size` of 1 for this purpose."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bcd4456",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:43.098416Z",
     "start_time": "2021-06-25T03:05:43.084811Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size of 1\n",
      "0 Text data:  [('me',), ('gusta',), ('comer',), ('en',), ('la',), ('cafeteria',)]\n",
      "0 Label data:  ['SPANISH']\n",
      "1 Text data:  [('Give',), ('it',), ('to',), ('me',)]\n",
      "1 Label data:  ['ENGLISH']\n",
      "2 Text data:  [('No',), ('creo',), ('que',), ('sea',), ('una',), ('buena',), ('idea',)]\n",
      "2 Label data:  ['SPANISH']\n",
      "3 Text data:  [('No',), ('it',), ('is',), ('not',), ('a',), ('good',), ('idea',), ('to',), ('get',), ('lost',), ('at',), ('sea',)]\n",
      "3 Label data:  ['ENGLISH']\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 8;\n",
       "                var nbb_unformatted_code = \"train_DL = DataLoader(train_DS1, batch_size=1, shuffle=False)\\n\\nprint(\\\"Batch size of 1\\\")\\nfor (idx, batch) in enumerate(train_DL):  # Print the 'text' data of the batch\\n\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])  # Print the 'class' data of batch\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"])\";\n",
       "                var nbb_formatted_code = \"train_DL = DataLoader(train_DS1, batch_size=1, shuffle=False)\\n\\nprint(\\\"Batch size of 1\\\")\\nfor (idx, batch) in enumerate(train_DL):  # Print the 'text' data of the batch\\n\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])  # Print the 'class' data of batch\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_DL = DataLoader(train_DS1, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"Batch size of 1\")\n",
    "for (idx, batch) in enumerate(train_DL):  # Print the 'text' data of the batch\n",
    "\n",
    "    print(idx, \"Text data: \", batch[\"Text\"])  # Print the 'class' data of batch\n",
    "    print(idx, \"Label data: \", batch[\"Label\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a58cdaa",
   "metadata": {},
   "source": [
    "At first glance, things might look okay but the eagle-eyed will notice that each element in our list is now wrapped as one element. If we increase `batch_size` to 2, we get an [ugly error](https://media.giphy.com/media/eGNtzon6aSbPA6qgU4/giphy.gif)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28d14cf1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:44.926047Z",
     "start_time": "2021-06-25T03:05:44.697063Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size of 2\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "each element in list of batch should be of equal size",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-b81921277760>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Batch size of 2\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_DL2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# Print the 'text' data of the batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Text data: \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Text\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Print the 'class' data of batch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sdoh_text/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    515\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sampler_iter\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    516\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 517\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    518\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    519\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_kind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0m_DatasetKind\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mIterable\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sdoh_text/lib/python3.8/site-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    555\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 557\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    558\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sdoh_text/lib/python3.8/site-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     45\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 47\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcollate_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/envs/sdoh_text/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sdoh_text/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     71\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcontainer_abcs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMapping\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mbatch\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0melem\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'_fields'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# namedtuple\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0melem_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/envs/sdoh_text/lib/python3.8/site-packages/torch/utils/data/_utils/collate.py\u001b[0m in \u001b[0;36mdefault_collate\u001b[0;34m(batch)\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0melem_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0melem_size\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0melem\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'each element in list of batch should be of equal size'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0mtransposed\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mbatch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mdefault_collate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0msamples\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtransposed\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: each element in list of batch should be of equal size"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 9;\n",
       "                var nbb_unformatted_code = \"train_DL2 = DataLoader(train_DS1, batch_size=2, shuffle=False)\\n\\nprint(\\\"Batch size of 2\\\")\\nfor (idx, batch) in enumerate(train_DL2):  # Print the 'text' data of the batch\\n\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])  # Print the 'class' data of batch\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"train_DL2 = DataLoader(train_DS1, batch_size=2, shuffle=False)\\n\\nprint(\\\"Batch size of 2\\\")\\nfor (idx, batch) in enumerate(train_DL2):  # Print the 'text' data of the batch\\n\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])  # Print the 'class' data of batch\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_DL2 = DataLoader(train_DS1, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"Batch size of 2\")\n",
    "for (idx, batch) in enumerate(train_DL2):  # Print the 'text' data of the batch\n",
    "\n",
    "    print(idx, \"Text data: \", batch[\"Text\"])  # Print the 'class' data of batch\n",
    "    print(idx, \"Label data: \", batch[\"Label\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55be0c8d",
   "metadata": {},
   "source": [
    "What's going on? With some investigation of which I'll spare you, it appears that having each sample data already as a list makes confuses `Dataloader`. Let's re-structure out data differently."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a4b584",
   "metadata": {},
   "source": [
    "# Re-structuring data as a comma-separated string"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "591cf32e",
   "metadata": {},
   "source": [
    "Due to the structure of our model, we still need a way to vectorize each sentence sample, but we can't have each wrapped as a list. Here is a workaround even if the syntax is awkward. I'm rejoining the elements as a comma-separated string like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e1834a60",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:48.004839Z",
     "start_time": "2021-06-25T03:05:47.998499Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'me, gusta, comer, en, la, cafeteria'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 10;\n",
       "                var nbb_unformatted_code = \"\\\", \\\".join(\\\"me gusta comer en la cafeteria\\\".split())\";\n",
       "                var nbb_formatted_code = \"\\\", \\\".join(\\\"me gusta comer en la cafeteria\\\".split())\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\", \".join(\"me gusta comer en la cafeteria\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0114efeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:48.948352Z",
     "start_time": "2021-06-25T03:05:48.932808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 11;\n",
       "                var nbb_unformatted_code = \"train_data2 = [\\n    (\\\", \\\".join(\\\"me gusta comer en la cafeteria\\\".split()), \\\"SPANISH\\\"),\\n    (\\\", \\\".join(\\\"Give it to me\\\".split()), \\\"ENGLISH\\\"),\\n    (\\\", \\\".join(\\\"No creo que sea una buena idea\\\".split()), \\\"SPANISH\\\"),\\n    (\\\", \\\".join(\\\"No it is not a good idea to get lost at sea\\\".split()), \\\"ENGLISH\\\"),\\n]\\n\\ntest_data2 = [\\n    (\\\", \\\".join(\\\"Yo creo que si\\\".split()), \\\"SPANISH\\\"),\\n    (\\\", \\\".join(\\\"it is lost on me\\\".split()), \\\"ENGLISH\\\"),\\n]\";\n",
       "                var nbb_formatted_code = \"train_data2 = [\\n    (\\\", \\\".join(\\\"me gusta comer en la cafeteria\\\".split()), \\\"SPANISH\\\"),\\n    (\\\", \\\".join(\\\"Give it to me\\\".split()), \\\"ENGLISH\\\"),\\n    (\\\", \\\".join(\\\"No creo que sea una buena idea\\\".split()), \\\"SPANISH\\\"),\\n    (\\\", \\\".join(\\\"No it is not a good idea to get lost at sea\\\".split()), \\\"ENGLISH\\\"),\\n]\\n\\ntest_data2 = [\\n    (\\\", \\\".join(\\\"Yo creo que si\\\".split()), \\\"SPANISH\\\"),\\n    (\\\", \\\".join(\\\"it is lost on me\\\".split()), \\\"ENGLISH\\\"),\\n]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_data2 = [\n",
    "    (\", \".join(\"me gusta comer en la cafeteria\".split()), \"SPANISH\"),\n",
    "    (\", \".join(\"Give it to me\".split()), \"ENGLISH\"),\n",
    "    (\", \".join(\"No creo que sea una buena idea\".split()), \"SPANISH\"),\n",
    "    (\", \".join(\"No it is not a good idea to get lost at sea\".split()), \"ENGLISH\"),\n",
    "]\n",
    "\n",
    "test_data2 = [\n",
    "    (\", \".join(\"Yo creo que si\".split()), \"SPANISH\"),\n",
    "    (\", \".join(\"it is lost on me\".split()), \"ENGLISH\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "88c93f73",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:49.684819Z",
     "start_time": "2021-06-25T03:05:49.678282Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 12;\n",
       "                var nbb_unformatted_code = \"data2 = train_data2 + test_data2\\ndf_data2 = pd.DataFrame(data2)\\ndf_data2.columns = [\\\"words\\\", \\\"labels\\\"]\";\n",
       "                var nbb_formatted_code = \"data2 = train_data2 + test_data2\\ndf_data2 = pd.DataFrame(data2)\\ndf_data2.columns = [\\\"words\\\", \\\"labels\\\"]\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "data2 = train_data2 + test_data2\n",
    "df_data2 = pd.DataFrame(data2)\n",
    "df_data2.columns = [\"words\", \"labels\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b202a5c",
   "metadata": {},
   "source": [
    "Here's how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "39ccec51",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:51.097796Z",
     "start_time": "2021-06-25T03:05:51.090536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>labels</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>me, gusta, comer, en, la, cafeteria</td>\n",
       "      <td>SPANISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Give, it, to, me</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No, creo, que, sea, una, buena, idea</td>\n",
       "      <td>SPANISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>No, it, is, not, a, good, idea, to, get, lost,...</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yo, creo, que, si</td>\n",
       "      <td>SPANISH</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>it, is, lost, on, me</td>\n",
       "      <td>ENGLISH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               words   labels\n",
       "0                me, gusta, comer, en, la, cafeteria  SPANISH\n",
       "1                                   Give, it, to, me  ENGLISH\n",
       "2               No, creo, que, sea, una, buena, idea  SPANISH\n",
       "3  No, it, is, not, a, good, idea, to, get, lost,...  ENGLISH\n",
       "4                                  Yo, creo, que, si  SPANISH\n",
       "5                               it, is, lost, on, me  ENGLISH"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 13;\n",
       "                var nbb_unformatted_code = \"df_data2\";\n",
       "                var nbb_formatted_code = \"df_data2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_data2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b985034",
   "metadata": {},
   "source": [
    "## Putting the data in `Dataset` and output with `Dataloader`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1b1eba4e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:53.004565Z",
     "start_time": "2021-06-25T03:05:52.993745Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 14;\n",
       "                var nbb_unformatted_code = \"train_DS2 = TextDataset(\\n    train_ids,\\n    df_data2.loc[train_ids, \\\"words\\\"].tolist(),\\n    df_data2.loc[train_ids, \\\"labels\\\"].tolist(),\\n)\\ntest_DS2 = TextDataset(\\n    test_ids,\\n    df_data2.loc[test_ids, \\\"words\\\"].tolist(),\\n    df_data2.loc[test_ids, \\\"labels\\\"].tolist(),\\n)\";\n",
       "                var nbb_formatted_code = \"train_DS2 = TextDataset(\\n    train_ids,\\n    df_data2.loc[train_ids, \\\"words\\\"].tolist(),\\n    df_data2.loc[train_ids, \\\"labels\\\"].tolist(),\\n)\\ntest_DS2 = TextDataset(\\n    test_ids,\\n    df_data2.loc[test_ids, \\\"words\\\"].tolist(),\\n    df_data2.loc[test_ids, \\\"labels\\\"].tolist(),\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_DS2 = TextDataset(\n",
    "    train_ids,\n",
    "    df_data2.loc[train_ids, \"words\"].tolist(),\n",
    "    df_data2.loc[train_ids, \"labels\"].tolist(),\n",
    ")\n",
    "test_DS2 = TextDataset(\n",
    "    test_ids,\n",
    "    df_data2.loc[test_ids, \"words\"].tolist(),\n",
    "    df_data2.loc[test_ids, \"labels\"].tolist(),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdc0f30c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:53.883027Z",
     "start_time": "2021-06-25T03:05:53.869291Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size of 1\n",
      "0 Text data:  ['me, gusta, comer, en, la, cafeteria']\n",
      "0 Label data:  ['SPANISH'] \n",
      "\n",
      "1 Text data:  ['Give, it, to, me']\n",
      "1 Label data:  ['ENGLISH'] \n",
      "\n",
      "2 Text data:  ['No, creo, que, sea, una, buena, idea']\n",
      "2 Label data:  ['SPANISH'] \n",
      "\n",
      "3 Text data:  ['No, it, is, not, a, good, idea, to, get, lost, at, sea']\n",
      "3 Label data:  ['ENGLISH'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 15;\n",
       "                var nbb_unformatted_code = \"train_DL2a = DataLoader(train_DS2, batch_size=1, shuffle=False)\\n\\nprint(\\\"batch size of 1\\\")\\nfor (idx, batch) in enumerate(train_DL2a):\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"train_DL2a = DataLoader(train_DS2, batch_size=1, shuffle=False)\\n\\nprint(\\\"batch size of 1\\\")\\nfor (idx, batch) in enumerate(train_DL2a):\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_DL2a = DataLoader(train_DS2, batch_size=1, shuffle=False)\n",
    "\n",
    "print(\"batch size of 1\")\n",
    "for (idx, batch) in enumerate(train_DL2a):\n",
    "    print(idx, \"Text data: \", batch[\"Text\"])\n",
    "    print(idx, \"Label data: \", batch[\"Label\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e624bf1",
   "metadata": {},
   "source": [
    "Great, we get closer to the expected output where we have one sample, represented as a string, in the list created by `DataLoader`. We still have to vectorize this before we input this into our model but we can worry about that later. Additionally, when we increase the `batch_size` we don't get an error anymore."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3c24d3c2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:55.643032Z",
     "start_time": "2021-06-25T03:05:55.631591Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size of 2\n",
      "0 Text data:  ['me, gusta, comer, en, la, cafeteria', 'Give, it, to, me']\n",
      "0 Label data:  ['SPANISH', 'ENGLISH'] \n",
      "\n",
      "1 Text data:  ['No, creo, que, sea, una, buena, idea', 'No, it, is, not, a, good, idea, to, get, lost, at, sea']\n",
      "1 Label data:  ['SPANISH', 'ENGLISH'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 16;\n",
       "                var nbb_unformatted_code = \"train_DL2b = DataLoader(train_DS2, batch_size=2, shuffle=False)\\n\\nprint(\\\"batch size of 2\\\")\\nfor (idx, batch) in enumerate(train_DL2b):\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"train_DL2b = DataLoader(train_DS2, batch_size=2, shuffle=False)\\n\\nprint(\\\"batch size of 2\\\")\\nfor (idx, batch) in enumerate(train_DL2b):\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_DL2b = DataLoader(train_DS2, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"batch size of 2\")\n",
    "for (idx, batch) in enumerate(train_DL2b):\n",
    "    print(idx, \"Text data: \", batch[\"Text\"])\n",
    "    print(idx, \"Label data: \", batch[\"Label\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a9cdee7",
   "metadata": {},
   "source": [
    "We can also verify that this works for our test set in its own `DataLoader` object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d21931df",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:57.206634Z",
     "start_time": "2021-06-25T03:05:57.196528Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "batch size of 2\n",
      "0 Text data:  ['Yo, creo, que, si', 'it, is, lost, on, me']\n",
      "0 Label data:  ['SPANISH', 'ENGLISH'] \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 17;\n",
       "                var nbb_unformatted_code = \"test_DL2b = DataLoader(test_DS2, batch_size=2, shuffle=False)\\n\\nprint(\\\"batch size of 2\\\")\\nfor (idx, batch) in enumerate(test_DL2b):\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"test_DL2b = DataLoader(test_DS2, batch_size=2, shuffle=False)\\n\\nprint(\\\"batch size of 2\\\")\\nfor (idx, batch) in enumerate(test_DL2b):\\n    print(idx, \\\"Text data: \\\", batch[\\\"Text\\\"])\\n    print(idx, \\\"Label data: \\\", batch[\\\"Label\\\"], \\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_DL2b = DataLoader(test_DS2, batch_size=2, shuffle=False)\n",
    "\n",
    "print(\"batch size of 2\")\n",
    "for (idx, batch) in enumerate(test_DL2b):\n",
    "    print(idx, \"Text data: \", batch[\"Text\"])\n",
    "    print(idx, \"Label data: \", batch[\"Label\"], \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f251b0e8",
   "metadata": {},
   "source": [
    "# Train model using `DataLoader` objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ffc1334d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:58.939650Z",
     "start_time": "2021-06-25T03:05:58.931190Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'me': 0, 'gusta': 1, 'comer': 2, 'en': 3, 'la': 4, 'cafeteria': 5, 'Give': 6, 'it': 7, 'to': 8, 'No': 9, 'creo': 10, 'que': 11, 'sea': 12, 'una': 13, 'buena': 14, 'idea': 15, 'is': 16, 'not': 17, 'a': 18, 'good': 19, 'get': 20, 'lost': 21, 'at': 22, 'Yo': 23, 'si': 24, 'on': 25}\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 18;\n",
       "                var nbb_unformatted_code = \"# word_to_ix maps each word in the vocab to a unique integer, which will be its\\n# index into the Bag of words vector\\nword_to_ix = {}\\nfor sent, _ in data:\\n    for word in sent:\\n        if word not in word_to_ix:\\n            word_to_ix[word] = len(word_to_ix)\\nprint(word_to_ix)\\n\\nVOCAB_SIZE = len(word_to_ix)\\nNUM_LABELS = 2\";\n",
       "                var nbb_formatted_code = \"# word_to_ix maps each word in the vocab to a unique integer, which will be its\\n# index into the Bag of words vector\\nword_to_ix = {}\\nfor sent, _ in data:\\n    for word in sent:\\n        if word not in word_to_ix:\\n            word_to_ix[word] = len(word_to_ix)\\nprint(word_to_ix)\\n\\nVOCAB_SIZE = len(word_to_ix)\\nNUM_LABELS = 2\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# word_to_ix maps each word in the vocab to a unique integer, which will be its\n",
    "# index into the Bag of words vector\n",
    "word_to_ix = {}\n",
    "for sent, _ in data:\n",
    "    for word in sent:\n",
    "        if word not in word_to_ix:\n",
    "            word_to_ix[word] = len(word_to_ix)\n",
    "print(word_to_ix)\n",
    "\n",
    "VOCAB_SIZE = len(word_to_ix)\n",
    "NUM_LABELS = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "5534f458",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:05:59.804280Z",
     "start_time": "2021-06-25T03:05:59.797549Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['me', 'gusta', 'comer']"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 19;\n",
       "                var nbb_unformatted_code = \"sent = \\\"me, gusta, comer\\\"\\nsent.split(\\\", \\\")\";\n",
       "                var nbb_formatted_code = \"sent = \\\"me, gusta, comer\\\"\\nsent.split(\\\", \\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sent = \"me, gusta, comer\"\n",
    "sent.split(\", \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "61a44f67",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:06:00.914579Z",
     "start_time": "2021-06-25T03:06:00.898836Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 20;\n",
       "                var nbb_unformatted_code = \"class BoWClassifier(nn.Module):  # inheriting from nn.Module!\\n    def __init__(self, num_labels, vocab_size):\\n        # calls the init function of nn.Module.  Dont get confused by syntax,\\n        # just always do it in an nn.Module\\n        super(BoWClassifier, self).__init__()\\n\\n        # Define the parameters that you will need.  In this case, we need A and b,\\n        # the parameters of the affine mapping.\\n        # Torch defines nn.Linear(), which provides the affine map.\\n        # Make sure you understand why the input dimension is vocab_size\\n        # and the output is num_labels!\\n        self.linear = nn.Linear(vocab_size, num_labels)\\n\\n        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\\n        # to worry about that here\\n\\n    def forward(self, bow_vec):\\n        # Pass the input through the linear layer,\\n        # then pass that through log_softmax.\\n        # Many non-linearities and other functions are in torch.nn.functional\\n        return F.log_softmax(self.linear(bow_vec), dim=1)\\n\\n\\ndef make_bow_vector(sentence, word_to_ix):\\n    \\\"\\\"\\\"\\n    Edited from original to get words wrapped in a list back\\n    \\\"\\\"\\\"\\n    sentence = sentence[0].split(\\\", \\\")\\n    vec = torch.zeros(len(word_to_ix))\\n    for word in sentence:\\n        vec[word_to_ix[word]] += 1\\n    return vec.view(1, -1)\\n\\n\\ndef make_target(label, label_to_ix):\\n    \\\"\\\"\\\"\\n    Altered to extract label from list\\n    \\\"\\\"\\\"\\n    return torch.LongTensor([label_to_ix[label[0]]])\";\n",
       "                var nbb_formatted_code = \"class BoWClassifier(nn.Module):  # inheriting from nn.Module!\\n    def __init__(self, num_labels, vocab_size):\\n        # calls the init function of nn.Module.  Dont get confused by syntax,\\n        # just always do it in an nn.Module\\n        super(BoWClassifier, self).__init__()\\n\\n        # Define the parameters that you will need.  In this case, we need A and b,\\n        # the parameters of the affine mapping.\\n        # Torch defines nn.Linear(), which provides the affine map.\\n        # Make sure you understand why the input dimension is vocab_size\\n        # and the output is num_labels!\\n        self.linear = nn.Linear(vocab_size, num_labels)\\n\\n        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\\n        # to worry about that here\\n\\n    def forward(self, bow_vec):\\n        # Pass the input through the linear layer,\\n        # then pass that through log_softmax.\\n        # Many non-linearities and other functions are in torch.nn.functional\\n        return F.log_softmax(self.linear(bow_vec), dim=1)\\n\\n\\ndef make_bow_vector(sentence, word_to_ix):\\n    \\\"\\\"\\\"\\n    Edited from original to get words wrapped in a list back\\n    \\\"\\\"\\\"\\n    sentence = sentence[0].split(\\\", \\\")\\n    vec = torch.zeros(len(word_to_ix))\\n    for word in sentence:\\n        vec[word_to_ix[word]] += 1\\n    return vec.view(1, -1)\\n\\n\\ndef make_target(label, label_to_ix):\\n    \\\"\\\"\\\"\\n    Altered to extract label from list\\n    \\\"\\\"\\\"\\n    return torch.LongTensor([label_to_ix[label[0]]])\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "class BoWClassifier(nn.Module):  # inheriting from nn.Module!\n",
    "    def __init__(self, num_labels, vocab_size):\n",
    "        # calls the init function of nn.Module.  Dont get confused by syntax,\n",
    "        # just always do it in an nn.Module\n",
    "        super(BoWClassifier, self).__init__()\n",
    "\n",
    "        # Define the parameters that you will need.  In this case, we need A and b,\n",
    "        # the parameters of the affine mapping.\n",
    "        # Torch defines nn.Linear(), which provides the affine map.\n",
    "        # Make sure you understand why the input dimension is vocab_size\n",
    "        # and the output is num_labels!\n",
    "        self.linear = nn.Linear(vocab_size, num_labels)\n",
    "\n",
    "        # NOTE! The non-linearity log softmax does not have parameters! So we don't need\n",
    "        # to worry about that here\n",
    "\n",
    "    def forward(self, bow_vec):\n",
    "        # Pass the input through the linear layer,\n",
    "        # then pass that through log_softmax.\n",
    "        # Many non-linearities and other functions are in torch.nn.functional\n",
    "        return F.log_softmax(self.linear(bow_vec), dim=1)\n",
    "\n",
    "\n",
    "def make_bow_vector(sentence, word_to_ix):\n",
    "    \"\"\"\n",
    "    Edited from original to get words wrapped in a list back\n",
    "    \"\"\"\n",
    "    sentence = sentence[0].split(\", \")\n",
    "    vec = torch.zeros(len(word_to_ix))\n",
    "    for word in sentence:\n",
    "        vec[word_to_ix[word]] += 1\n",
    "    return vec.view(1, -1)\n",
    "\n",
    "\n",
    "def make_target(label, label_to_ix):\n",
    "    \"\"\"\n",
    "    Altered to extract label from list\n",
    "    \"\"\"\n",
    "    return torch.LongTensor([label_to_ix[label[0]]])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b8351fa",
   "metadata": {},
   "source": [
    "## Batch size of 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e0887b03",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:06:02.253494Z",
     "start_time": "2021-06-25T03:06:02.247065Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 21;\n",
       "                var nbb_unformatted_code = \"train_DL2a = DataLoader(train_DS2, batch_size=1, shuffle=False)\\ntest_DL2a = DataLoader(test_DS2, batch_size=1, shuffle=False)\";\n",
       "                var nbb_formatted_code = \"train_DL2a = DataLoader(train_DS2, batch_size=1, shuffle=False)\\ntest_DL2a = DataLoader(test_DS2, batch_size=1, shuffle=False)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_DL2a = DataLoader(train_DS2, batch_size=1, shuffle=False)\n",
    "test_DL2a = DataLoader(test_DS2, batch_size=1, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9fc49e1c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:06:12.218561Z",
     "start_time": "2021-06-25T03:06:12.212644Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 25;\n",
       "                var nbb_unformatted_code = \"model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\";\n",
       "                var nbb_formatted_code = \"model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = BoWClassifier(NUM_LABELS, VOCAB_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "bb88d83f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:06:13.110622Z",
     "start_time": "2021-06-25T03:06:13.102660Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[ 0.0544,  0.0097,  0.0716, -0.0764, -0.0143, -0.0177,  0.0284, -0.0008,\n",
      "          0.1714,  0.0610, -0.0730, -0.1184, -0.0329, -0.0846, -0.0628,  0.0094,\n",
      "          0.1169,  0.1066, -0.1917,  0.1216,  0.0548,  0.1860,  0.1294, -0.1787,\n",
      "         -0.1865, -0.0946],\n",
      "        [ 0.1722, -0.0327,  0.0839, -0.0911,  0.1924, -0.0830,  0.1471,  0.0023,\n",
      "         -0.1033,  0.1008, -0.1041,  0.0577, -0.0566, -0.0215, -0.1885, -0.0935,\n",
      "          0.1064, -0.0477,  0.1953,  0.1572, -0.0092, -0.1309,  0.1194,  0.0609,\n",
      "         -0.1268,  0.1274]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([0.1191, 0.1739], requires_grad=True)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 26;\n",
       "                var nbb_unformatted_code = \"for param in model.parameters():\\n    print(param)\";\n",
       "                var nbb_formatted_code = \"for param in model.parameters():\\n    print(param)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for param in model.parameters():\n",
    "    print(param)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cda6b28",
   "metadata": {},
   "source": [
    "Note that model parameters are randomly initialized to very small, non-zero values so that gradient descent is not too slow. This point is explained more fully by Andrew Ng in [this video](https://www.youtube.com/watch?v=6by6Xas_Kho&list=PLkDaE6sCZn6Ec-XTbcX1uRg2_u4xOEky0&index=35)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0e846eb3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:12:13.458819Z",
     "start_time": "2021-06-25T03:12:13.453245Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 28;\n",
       "                var nbb_unformatted_code = \"label_to_ix = {\\\"SPANISH\\\": 0, \\\"ENGLISH\\\": 1}\";\n",
       "                var nbb_formatted_code = \"label_to_ix = {\\\"SPANISH\\\": 0, \\\"ENGLISH\\\": 1}\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "label_to_ix = {\"SPANISH\": 0, \"ENGLISH\": 1}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb22af9",
   "metadata": {},
   "source": [
    "### Run on test data before we train, just to see a before-and-after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "78c96019",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:12:29.804525Z",
     "start_time": "2021-06-25T03:12:29.786104Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo, creo, que, si'] ['SPANISH']\n",
      "tensor([[-0.9736, -0.4744]]) \n",
      "\n",
      "['it, is, lost, on, me'] ['ENGLISH']\n",
      "tensor([[-0.7289, -0.6586]]) \n",
      "\n",
      "Tensor for 'creo' (before training):  tensor([-0.0730, -0.1041], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 30;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    for batch in test_DL2a:\\n        # Alter code from tutorial\\n        # for instance, label in test_data:\\n        instance, label = batch[\\\"Text\\\"], batch[\\\"Label\\\"]\\n        print(instance, label)\\n\\n        bow_vec = make_bow_vector(instance, word_to_ix)\\n        log_probs = model(bow_vec)\\n        print(log_probs, \\\"\\\\n\\\")\\n\\n# Print the matrix column corresponding to \\\"creo\\\"\\nprint(\\\"Tensor for 'creo' (before training): \\\", next(model.parameters())[:, word_to_ix[\\\"creo\\\"]])\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    for batch in test_DL2a:\\n        # Alter code from tutorial\\n        # for instance, label in test_data:\\n        instance, label = batch[\\\"Text\\\"], batch[\\\"Label\\\"]\\n        print(instance, label)\\n\\n        bow_vec = make_bow_vector(instance, word_to_ix)\\n        log_probs = model(bow_vec)\\n        print(log_probs, \\\"\\\\n\\\")\\n\\n# Print the matrix column corresponding to \\\"creo\\\"\\nprint(\\n    \\\"Tensor for 'creo' (before training): \\\",\\n    next(model.parameters())[:, word_to_ix[\\\"creo\\\"]],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_DL2a:\n",
    "        # Alter code from tutorial\n",
    "        # for instance, label in test_data:\n",
    "        instance, label = batch[\"Text\"], batch[\"Label\"]\n",
    "        print(instance, label)\n",
    "\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs, \"\\n\")\n",
    "\n",
    "# Print the matrix column corresponding to \"creo\"\n",
    "print(\n",
    "    \"Tensor for 'creo' (before training): \",\n",
    "    next(model.parameters())[:, word_to_ix[\"creo\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2918362b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:12:31.555478Z",
     "start_time": "2021-06-25T03:12:31.403686Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, training sample: 0, loss = 0.8369\n",
      "epoch: 20, training sample: 0, loss = 0.0507\n",
      "epoch: 40, training sample: 0, loss = 0.0257\n",
      "epoch: 60, training sample: 0, loss = 0.0172\n",
      "epoch: 80, training sample: 0, loss = 0.0129\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 31;\n",
       "                var nbb_unformatted_code = \"loss_function = nn.NLLLoss()\\noptimizer = optim.SGD(model.parameters(), lr=0.1)\\n\\nfor epoch in range(100):\\n    # for instance, label in data:\\n\\n    for (idx, batch) in enumerate(train_DL2a):  # Print the 'text' data of the batch\\n        instance, label = batch[\\\"Text\\\"], batch[\\\"Label\\\"]\\n\\n        # Step 1. Remember that PyTorch accumulates gradients.\\n        # We need to clear them out before each instance\\n        model.zero_grad()\\n\\n        # Step 2. Make our BOW vector and also we must wrap the target in a\\n        # Tensor as an integer. For example, if the target is SPANISH, then\\n        # we wrap the integer 0. The loss function then knows that the 0th\\n        # element of the log probabilities is the log probability\\n        # corresponding to SPANISH\\n        bow_vec = make_bow_vector(instance, word_to_ix)\\n        target = make_target(label, label_to_ix)\\n\\n        # Step 3. Run our forward pass.\\n        log_probs = model(bow_vec)\\n\\n        # Step 4. Compute the loss, gradients, and update the parameters by\\n        # calling optimizer.step()\\n        loss = loss_function(log_probs, target)\\n        loss.backward()\\n        optimizer.step()\\n\\n        if (idx % 4 == 0) & (epoch % 20 == 0):  # Edit when datasets are bigger\\n            print(f\\\"epoch: {epoch}, training sample: {idx}, loss = {loss.item():0.04f}\\\")\";\n",
       "                var nbb_formatted_code = \"loss_function = nn.NLLLoss()\\noptimizer = optim.SGD(model.parameters(), lr=0.1)\\n\\nfor epoch in range(100):\\n    # for instance, label in data:\\n\\n    for (idx, batch) in enumerate(train_DL2a):  # Print the 'text' data of the batch\\n        instance, label = batch[\\\"Text\\\"], batch[\\\"Label\\\"]\\n\\n        # Step 1. Remember that PyTorch accumulates gradients.\\n        # We need to clear them out before each instance\\n        model.zero_grad()\\n\\n        # Step 2. Make our BOW vector and also we must wrap the target in a\\n        # Tensor as an integer. For example, if the target is SPANISH, then\\n        # we wrap the integer 0. The loss function then knows that the 0th\\n        # element of the log probabilities is the log probability\\n        # corresponding to SPANISH\\n        bow_vec = make_bow_vector(instance, word_to_ix)\\n        target = make_target(label, label_to_ix)\\n\\n        # Step 3. Run our forward pass.\\n        log_probs = model(bow_vec)\\n\\n        # Step 4. Compute the loss, gradients, and update the parameters by\\n        # calling optimizer.step()\\n        loss = loss_function(log_probs, target)\\n        loss.backward()\\n        optimizer.step()\\n\\n        if (idx % 4 == 0) & (epoch % 20 == 0):  # Edit when datasets are bigger\\n            print(f\\\"epoch: {epoch}, training sample: {idx}, loss = {loss.item():0.04f}\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "loss_function = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.1)\n",
    "\n",
    "for epoch in range(100):\n",
    "    # for instance, label in data:\n",
    "\n",
    "    for (idx, batch) in enumerate(train_DL2a):  # Print the 'text' data of the batch\n",
    "        instance, label = batch[\"Text\"], batch[\"Label\"]\n",
    "\n",
    "        # Step 1. Remember that PyTorch accumulates gradients.\n",
    "        # We need to clear them out before each instance\n",
    "        model.zero_grad()\n",
    "\n",
    "        # Step 2. Make our BOW vector and also we must wrap the target in a\n",
    "        # Tensor as an integer. For example, if the target is SPANISH, then\n",
    "        # we wrap the integer 0. The loss function then knows that the 0th\n",
    "        # element of the log probabilities is the log probability\n",
    "        # corresponding to SPANISH\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        target = make_target(label, label_to_ix)\n",
    "\n",
    "        # Step 3. Run our forward pass.\n",
    "        log_probs = model(bow_vec)\n",
    "\n",
    "        # Step 4. Compute the loss, gradients, and update the parameters by\n",
    "        # calling optimizer.step()\n",
    "        loss = loss_function(log_probs, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (idx % 4 == 0) & (epoch % 20 == 0):  # Edit when datasets are bigger\n",
    "            print(f\"epoch: {epoch}, training sample: {idx}, loss = {loss.item():0.04f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d7bc4a0",
   "metadata": {},
   "source": [
    "We see the loss decrease quickly and saturate by the end of the training epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d6ee77e",
   "metadata": {},
   "source": [
    "### Evaluation after training\n",
    "\n",
    "Look at the test set again, after model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d1fc84c1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:13:16.338254Z",
     "start_time": "2021-06-25T03:13:16.326340Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Yo, creo, que, si'] ['SPANISH']\n",
      "tensor([[-0.2056, -1.6828]]) \n",
      "\n",
      "['it, is, lost, on, me'] ['ENGLISH']\n",
      "tensor([[-2.7960, -0.0630]]) \n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 32;\n",
       "                var nbb_unformatted_code = \"with torch.no_grad():\\n    for batch in test_DL2a:\\n        # Alter code from tutorial\\n        # for instance, label in test_data:\\n        instance, label = batch[\\\"Text\\\"], batch[\\\"Label\\\"]\\n        print(instance, label)\\n\\n        bow_vec = make_bow_vector(instance, word_to_ix)\\n        log_probs = model(bow_vec)\\n        print(log_probs, \\\"\\\\n\\\")\";\n",
       "                var nbb_formatted_code = \"with torch.no_grad():\\n    for batch in test_DL2a:\\n        # Alter code from tutorial\\n        # for instance, label in test_data:\\n        instance, label = batch[\\\"Text\\\"], batch[\\\"Label\\\"]\\n        print(instance, label)\\n\\n        bow_vec = make_bow_vector(instance, word_to_ix)\\n        log_probs = model(bow_vec)\\n        print(log_probs, \\\"\\\\n\\\")\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    for batch in test_DL2a:\n",
    "        # Alter code from tutorial\n",
    "        # for instance, label in test_data:\n",
    "        instance, label = batch[\"Text\"], batch[\"Label\"]\n",
    "        print(instance, label)\n",
    "\n",
    "        bow_vec = make_bow_vector(instance, word_to_ix)\n",
    "        log_probs = model(bow_vec)\n",
    "        print(log_probs, \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "52d850d7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:13:27.984687Z",
     "start_time": "2021-06-25T03:13:27.974508Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix for 'creo' (after training):  tensor([ 0.3702, -0.5473], grad_fn=<SelectBackward>)\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 33;\n",
       "                var nbb_unformatted_code = \"# Print the matrix column corresponding to \\\"creo\\\"\\nprint(\\n    \\\"Matrix for 'creo' (after training): \\\",\\n    next(model.parameters())[:, word_to_ix[\\\"creo\\\"]],\\n)\";\n",
       "                var nbb_formatted_code = \"# Print the matrix column corresponding to \\\"creo\\\"\\nprint(\\n    \\\"Matrix for 'creo' (after training): \\\",\\n    next(model.parameters())[:, word_to_ix[\\\"creo\\\"]],\\n)\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Print the matrix column corresponding to \"creo\"\n",
    "print(\n",
    "    \"Matrix for 'creo' (after training): \",\n",
    "    next(model.parameters())[:, word_to_ix[\"creo\"]],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44c3e61a",
   "metadata": {},
   "source": [
    "We see that the coefficients for the Spanish word \"creo\" separate quite nicely and relative to the initial values. [I believe](https://media.giphy.com/media/U8GLl0bUYFLZVquOfY/giphy.gif) that the model training was successful."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fd7f42b",
   "metadata": {},
   "source": [
    "# Summary\n",
    "\n",
    "In this post, I sought to better understand how to use `Dataset` and `Dataloader` objects, especially in the context of model training. Fleshing this out showed me where I had to re-structure my data to get my code to work properly. Here, I had a batch size of 1, to mimic the original PyTorch tutorial. In a later post, I'll write about how to take advantage of batching which is more relevant in larger datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sufficient-corporation",
   "metadata": {},
   "source": [
    "Appendix: Environment and system parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "racial-charlotte",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-25T03:18:35.428540Z",
     "start_time": "2021-06-25T03:18:35.402715Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last updated: Thu Jun 24 2021\n",
      "\n",
      "Python implementation: CPython\n",
      "Python version       : 3.8.6\n",
      "IPython version      : 7.22.0\n",
      "\n",
      "numpy  : 1.19.5\n",
      "torch  : 1.8.1\n",
      "re     : 2.2.1\n",
      "json   : 2.0.9\n",
      "seaborn: 0.11.1\n",
      "pandas : 1.2.1\n",
      "\n",
      "Watermark: 2.1.0\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/javascript": [
       "\n",
       "            setTimeout(function() {\n",
       "                var nbb_cell_id = 34;\n",
       "                var nbb_unformatted_code = \"%watermark -n -u -v -iv -w\";\n",
       "                var nbb_formatted_code = \"%watermark -n -u -v -iv -w\";\n",
       "                var nbb_cells = Jupyter.notebook.get_cells();\n",
       "                for (var i = 0; i < nbb_cells.length; ++i) {\n",
       "                    if (nbb_cells[i].input_prompt_number == nbb_cell_id) {\n",
       "                        if (nbb_cells[i].get_text() == nbb_unformatted_code) {\n",
       "                             nbb_cells[i].set_text(nbb_formatted_code);\n",
       "                        }\n",
       "                        break;\n",
       "                    }\n",
       "                }\n",
       "            }, 500);\n",
       "            "
      ],
      "text/plain": [
       "<IPython.core.display.Javascript object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%watermark -n -u -v -iv -w"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "toc-autonumbering": true,
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "503.85px",
    "left": "1490px",
    "right": "20px",
    "top": "120px",
    "width": "282px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
