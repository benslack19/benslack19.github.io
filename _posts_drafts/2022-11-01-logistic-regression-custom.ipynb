{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating custom estimator function in sklearn**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.special import expit\n",
    "import scipy.optimize as opt  \n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Custom Sklearn function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.metrics import euclidean_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "class myLogisticRegression(BaseEstimator):\n",
    "\n",
    "    def __init__(self): #, param1=1, param2=2, theta=3):\n",
    "        pass\n",
    "        # self.param1 = param1\n",
    "        # self.param2 = param2\n",
    "        # self.theta = theta\n",
    "\n",
    "    def sigmoid(self, z):\n",
    "        return (1 / (1 + np.exp(-z)))\n",
    "\n",
    "    def costFunction(self, theta, X, y):\n",
    "        # Initialize some useful values\n",
    "        (m, n) = X.shape\n",
    "        J = 0\n",
    "        grad = np.zeros(theta.shape)\n",
    "        #print(\"shapes\", theta.shape,X.shape, y.shape)\n",
    "        \n",
    "        h = self.sigmoid(np.dot(X, theta)).flatten()\n",
    "        step1 = np.dot(y.T, np.log(h))\n",
    "        step2 = np.dot((1-y).T, np.log(1-h))\n",
    "        J = (1/m)*(-step1-step2)\n",
    "        grad = (1/m)*(np.dot(X.T,(h-y)))\n",
    "        return (J, grad)\n",
    "\n",
    "    def fit(self, X, y, theta):\n",
    "\n",
    "        # Check that X and y have correct shape\n",
    "        X, y = check_X_y(X, y)\n",
    "        # Store the classes seen during fit\n",
    "        self.classes_ = unique_labels(y)\n",
    "\n",
    "        (m, n) = X.shape\n",
    "\n",
    "        (cost, grad) = self.costFunction(theta, X, y)\n",
    "        print('Initial thetas: ', theta);\n",
    "        print('Cost at initial theta (zeros): ', cost);\n",
    "        print('Gradient at initial theta: \\n', grad);\n",
    "\n",
    "        # Run gradient descent\n",
    "        result = opt.fmin_tnc(func=self.costFunction, x0=theta, args=(X, y))\n",
    "\n",
    "        self.fitted_theta_ = result[0]\n",
    "        optimal_theta = result[0]\n",
    "        \n",
    "        (cost, grad) = self.costFunction(self.fitted_theta_ , X, y)\n",
    "        print('Gradient at final theta: \\n', grad)\n",
    "        print('Cost at final theta: ', cost);\n",
    "        print('final thetas: ', optimal_theta);\n",
    "\n",
    "        self.X_ = X\n",
    "        self.y_ = y\n",
    "        self.fitted_theta_ = y\n",
    "\n",
    "        # Return the classifier\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.random.normal(0, 1, size=60).reshape([20, 3])\n",
    "# Add intercept term to x and X_test\n",
    "X = np.concatenate((np.ones((m,1)), X), axis=1)\n",
    "\n",
    "# input coefficients\n",
    "betas = [0.1, 0.5, 1, 2]\n",
    "y_prob = expit(np.dot(X, betas))\n",
    "y = np.array(y_prob > 0.5).astype(int)\n",
    "\n",
    "(m, n) = X.shape\n",
    "initial_theta = np.zeros((n, 1))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_model = myLogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial thetas:  [[0.]\n",
      " [0.]\n",
      " [0.]\n",
      " [0.]]\n",
      "Cost at initial theta (zeros):  0.6931471805599453\n",
      "Gradient at initial theta: \n",
      " [ 0.1        -0.14044735 -0.35111288 -0.35554127]\n",
      "Gradient at final theta: \n",
      " [-0.00141083  0.00077872 -0.00252574 -0.00090012]\n",
      "Cost at final theta:  0.00826826879578249\n",
      "final thetas:  [-0.67292536  6.03019816  7.49616138 11.86148422]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  NIT   NF   F                       GTG\n",
      "    0    1  6.931471805599453E-01   2.79415307E-01\n",
      "tnc: stepmx = 1000\n",
      "    1    5  1.399664067356861E-01   6.71166699E-03\n",
      "    2    8  2.839803150442382E-02   1.41910649E-04\n",
      "tnc: fscale = 83.9446\n",
      "    3   11  1.778317789605917E-02   2.55147283E-05\n",
      "/var/folders/tw/b9j0wcdj6_9cyljwt364lx7c0000gn/T/ipykernel_10949/2420188656.py:21: RuntimeWarning: divide by zero encountered in log\n",
      "  step2 = np.dot((1-y).T, np.log(1-h))\n",
      "    4   38  8.268268919439081E-03   9.78643010E-06\n",
      "tnc: |fn-fn-1] = 1.23657e-10 -> convergence\n",
      "    5   90  8.268268795782491E-03   9.78642982E-06\n",
      "tnc: Converged (|f_n-f_(n-1)| ~= 0)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-16 {color: black;background-color: white;}#sk-container-id-16 pre{padding: 0;}#sk-container-id-16 div.sk-toggleable {background-color: white;}#sk-container-id-16 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-16 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-16 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-16 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-16 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-16 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-16 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-16 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-16 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-16 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-16 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-16 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-16 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-16 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-16 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-16 div.sk-item {position: relative;z-index: 1;}#sk-container-id-16 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-16 div.sk-item::before, #sk-container-id-16 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-16 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-16 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-16 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-16 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-16 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-16 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-16 div.sk-label-container {text-align: center;}#sk-container-id-16 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-16 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-16\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>myLogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">myLogisticRegression</label><div class=\"sk-toggleable__content\"><pre>myLogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "myLogisticRegression()"
      ]
     },
     "execution_count": 313,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_model.fit(X, y, initial_theta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = LogisticRegression(penalty='none')\n",
    "model = model.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.56292802, 14.10190926, 20.84767108, 38.40944439])"
      ]
     },
     "execution_count": 316,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.coef_[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.11 ('sdoh_text2')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "625px",
    "left": "0px",
    "right": "833px",
    "top": "106px",
    "width": "268px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "de5cbdcc76c98b93c5b7f180fb4e26c4c9428508be3211495db9b182446cc4e4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
